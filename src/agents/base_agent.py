
from typing import List, Optional
from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage, AIMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import tool
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.types import interrupt
from core.state import AgentState


load_dotenv()

@tool
def search_web(query: str):
    """
    Perform a web search for information related to the user's query. This tool call should follow a call to perform_rag, which will help in identifying relevant documents and resources.
    The web search should be performed only if the relevant results obtained from the perform_rag tool do not provide enough information to answer the user's query, and the user is not satisfied with the information provided.
    
    The user should be asked if they are satisfied with the information provided by the web search, using the determine_user_sentiment tool.
    If the user is not satisfied, ask the user if they would like to send an email to the advisor for further assistance.
    """
    return f"Web search results for query: {query}"  # Example response

@tool
def vectorize_user_input(user_input: str) -> List[float]:
    """ Vectorize user input for further processing.
    
    Unless a user explicitly requests to send an email, or to look up an advisor, this tool call should be the first step in generating a response. 
    The vectorized input should be used to perform RAG and generate a response, performed by the perform_rag tool.
    """
    return [-0.2, 0.1, 0.3, -0.1, 0.2]  # Example vectorized input

@tool
def perform_rag(user_query_vector: List[float]):
    """You have access to a large corpus of documents and resources related to the Univeristy of West Florida to answer the user's query. 
    Perform Retrieval-Augmented Generation (RAG) on the vectorized user input, generated by the vectorize_user_input tool. This tool call should follow a call to vectorize_user_input.
    The RAG process will help in generating a more accurate and relevant response to the user's query.
    The RAG process will also help in identifying relevant documents and resources that can be used to answer the user's query.

    
    Once the relevant results are obtained, return the results to the user. The results should include the most relevant documents and resources that can be used to answer the user's query.
    The results should also include a summary of the most relevant information found in the documents and resources.If the relevant results include a URL, include it in the response as well. 
    
    You should then ask the user if they are satisfied with the information provided, using the determine_user_sentiment tool.
    If the user is not satisfied, ask the user if they would like you to perform a web search for more information, or if they would like to send an email to the advisor for further assistance.
    If the user agrees, perform a web search using the search_web tool and return the results to the user.
    """
    return "Relevant results from RAG process"  # Example response 

@tool
def draft_email(user_input: str, advisor_email: str, advisor_name: str, student_name: str, student_email: str):
    """ Draft an email based on user input. This email will be used to communicate with the advisor. 
    The email should include the name of the student, the student's email address,the advisor's name, and a brief summary of the user's query. 
    The tone should be professional and courteous.
    
    This tool call should follow a call to search_for_advisor, which will help in identifying the advisor's email address and name.
    The email should be sent using the send_email tool.

    This tool call should be performed only if explicitly requested by the user, or if the user is not satisfied with the information provided by the RAG process or the web search.
    """
    #TODO: Implement the email response structure
    pass

@tool
def send_email(email_content: str):
    """ Send an email with the drafted content. This tool call should follow a call to draft_email.
    The email should be sent to the advisor's email address, as identified using the search_for_advisor tool."""

    pass

@tool
def search_for_advisor(department: str):
    """Search for an advisor based on the student's department. If the department is not specified, the tool will prompt the user to specify their department.
    If the department is specified, the tool will search for an advisor in that department.
    Once the advisor is found, return the email address of the advisor to the user.
    Then, ask the user if they would like to draft and send an email to the advisor for further assistance.
    If the user agrees, draft an email using the draft_email tool. 
    """
    if not department:
        prompt = "Could you please specify your department?"
        department = interrupt(prompt)

    fake_department_advisors = {
        "Computer Science": {"name": "Dr. Smith", "email": "jane.smith@uwf.edu"}, 
        "Mathematics": {"name": "Dr. Johnson", "email": "john.johnson@uwf.edu"},
        "Biology": {"name": "Dr. Lee", "email": "sarah.lee@uwf.edu"},
        "History": {"name": "Dr. Brown", "email": "michael.brown@uwf.edu"}
    }

    try:
        advisor_info = fake_department_advisors[department]
        advisor_name = advisor_info["name"]
        advisor_email = advisor_info["email"]
    except KeyError:
        return "I'm sorry, I couldn't find an advisor for that department. Please check the department name and try again."
    
    return f"Advisor found. Your advisor is {advisor_name} at {advisor_email}."  # Example response

@tool
def end_conversation() -> str:
    """ If the user is satisfied with the information provided, or if the user explicitly requests to end the conversation, this tool call should be used to end the conversation.
    Additional indications include "I'm done", "I'm satisfied", "I'm happy", "I'm good", "I'm fine", "I'm all set", "I'm all good", "I'm all set", "goodbye".
    """
    return "Conversation ended"  # Example response

@tool
def determine_user_sentiment(user_input: str):
    """Determine the user's sentiment based on their input.
    If the user is satisfied with the information provided, or if the user explicitly requests to end the conversation, use the end_conversation tool to end the conversation.
    If the user is not satisfied with the information provided, ask the user if they would like you to perform a web search for more information, or if they would like to send an email to the advisor for further assistance.
    """
    prompt = "Are you satisfied with the information provided?"
    answer = interrupt(prompt)
    return answer

# Register the available tools
tools = [search_web, vectorize_user_input, perform_rag, draft_email, send_email, search_for_advisor, end_conversation, determine_user_sentiment]

# Initialize the model with the available tools
model = ChatGoogleGenerativeAI(model="gemini-3-pro-preview", include_thoughts=True).bind_tools(tools) # Bind available tools to the model

def base_agent(state: AgentState) -> AgentState:
    system_prompt = SystemMessage(content = f"""
        You are an AI assistant designed to help students with their academic and administrative tasks. 
        Your primary goal is to help answer students' questions and provide guidance on various topics. You may send an email to the advisor for further assistance if the user is not satisfied with the information provided.
        You only have access to information related to the University of West Florida.
        You have access to a variety of tools to assist with these tasks : {tools}

        The user will provide input, and you will use the available tools to generate a response. 
        Unless the user has explicitly requested to send an email, or to look up an advisor, the first step in generating a response should be to vectorize the user's input using the vectorize_user_input tool.
        Once the user's input is vectorized, you should perform retrieval augmented generation (RAG) on the vectorized input using the perform_rag tool.
        If the user is not satisfied with the information provided by the RAG process, you should ask the user if they would like you to perform a web search for more information, or if they would like to send an email to the advisor for further assistance.
        If the user agrees to perform a web search, use the search_web tool to perform the search and return the results to the user.
        If the user agrees to send an email, first search for the advisor using the search_for_advisor tool. 
        Once the advisor is found, draft an email using the draft_email tool and return it to the user for review.
        Once the user is satisfied, send the email using the send_email tool.

        After providing information from any tool call, always use the determine_user_sentiment tool to ask the user if they are satisfied with the information provided.

        If the user is satisfied with the information provided, or if the user explicitly requests to end the conversation, first ask the user if they have any additional questions. 
        If the user has no additional questions, use the end_conversation tool to end the conversation.
        """)

    # Rules first + conversation history + most recent user message
    all_messages = [system_prompt] + list(state["messages"]) + [user_message]

    # Generate a response using the model
    response = model.invoke(all_messages)

    content = response.content

    if content[0]["type"] == "thinking":
        print(f"\nAI thoughts: {content[0]['thinking']} ")
    
    # Print the response and the tools used
    print(f"\n AI Text: {response.text}")
    if hasattr(response, "tool_calls") and response.tool_calls:
        print(f"\nUSING TOOLS: {[tc['name'] for tc in response.tool_calls]}")
    

    # Update the state by returning the old messages + the new user message + the new AI response
    return {"messages": list(state["messages"]) + [user_message, response]}

def should_continue(state: AgentState): # Conditional function to determine if the graph should continue or end
    messages = state["messages"]
    last_message = messages[-1]
    if isinstance(last_message, AIMessage) and not last_message.tool_calls: # Look at last message to see if there are any tool calls. If not, end the graph.
        return "end" # Edge
    else: # If there are tool calls, continue the graph.
        return "continue" # Edge
    
def print_messages(messages):
    """ Print the message in a more readable format."""
    if not messages:
        return
    
    for message in messages[-3:]:
        if isinstance(message, ToolMessage):
            print(f"\n TOOL RESULT: {message.content}")

graph = StateGraph(AgentState)
graph.add_node("base_agent", base_agent)
graph.add_node("tool_node", ToolNode(tools))

graph.set_entry_point("base_agent")
graph.add_conditional_edges(
    source = "base_agent", 
    path = should_continue,
    path_map = {
        "continue": "tool_node",
        "end": END
    
    }
)
graph.add_edge("tool_node", "base_agent")

app = graph.compile()

user_input = input("User: ")
user_message = HumanMessage(content=user_input)
state = AgentState(messages=[user_message])

for step in app.stream(state, stream_mode="values"): #type: ignore
    if "messages" in step:
        print_messages(step["messages"])
    





